{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b70773e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import json\n",
    "import PIL\n",
    "\n",
    "\n",
    "from handler import geozoom_handler\n",
    "# from helpers import *\n",
    "from fc_net import *\n",
    "from utils import *\n",
    "from sa import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "281be808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.sample(range(0, len(image_names)), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9f365a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 municipalities.\n"
     ]
    }
   ],
   "source": [
    "image_names = get_png_names(\"../pooling/data/MEX2/\")[0:5]\n",
    "# image_names = get_png_names(\"../pooling/data/MEX2/\")\n",
    "# image_indices = random.sample(range(0, len(image_names)), 1000)\n",
    "# image_names = [image_names[i] for i in range(len(image_names)) if i in image_indices]\n",
    "y = get_migrants(\"../pooling/data/migration_data.json\" , image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3be71975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../pooling/data/MEX2/484002003/pngs/484002003_2010_1_box484002003_MAY.png',\n",
       " '../pooling/data/MEX2/484002004/pngs/484002004_2010_1_box484002004_MAY.png',\n",
       " '../pooling/data/MEX2/484004001/pngs/484004001_2010_1_box484004001_MAY.png',\n",
       " '../pooling/data/MEX2/484004004/pngs/484004004_2010_1_box484004004_MAY.png',\n",
       " '../pooling/data/MEX2/484004006/pngs/484004006_2010_1_box484004006_MAY.png']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17521165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in image_names:\n",
    "#     print(load_inputs(i).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8eb3bf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet18 = models.resnet18().to(device)\n",
    "attn_model = attnNet(resnet = resnet18).to(device)\n",
    "lr = .001\n",
    "criterion = torch.nn.L1Loss(reduction = 'mean')\n",
    "attn_optimizer = torch.optim.Adam(attn_model.parameters(), lr = lr)\n",
    "\n",
    "fc_model = fc_net(resnet = resnet18).to(device)\n",
    "fc_optimizer = torch.optim.Adam(fc_model.parameters(), lr = .01)\n",
    "\n",
    "butler = geozoom_handler(attn_model, \n",
    "                         fc_model, device, \n",
    "                         criterion, \n",
    "                         attn_optimizer, \n",
    "                         fc_optimizer, \n",
    "                         num_thresholds = 4,\n",
    "                         reduction_percent = .90,\n",
    "                         convergence_dims = (358, 284),\n",
    "                         plot = False, \n",
    "                         v = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19c40774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelfAttention(\n",
       "  (query_conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (key_conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (value_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (softmax): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_model.sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0903a9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "SPLIT = .60\n",
    "\n",
    "train_dl, val_dl = butler.prep_attn_data(image_names, y, SPLIT, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2559b623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('../pooling/data/MEX2/484004001/pngs/484004001_2010_1_box484004001_MAY.png',)\n",
      "('../pooling/data/MEX2/484002003/pngs/484002003_2010_1_box484002003_MAY.png',)\n",
      "('../pooling/data/MEX2/484002004/pngs/484002004_2010_1_box484002004_MAY.png',)\n"
     ]
    }
   ],
   "source": [
    "for i,o in train_dl:\n",
    "    print(i)\n",
    "#     print(load_inputs(i[0]).shape, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58ac6136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "  Training Loss:  13872.653672059378\n",
      "  Validation Loss:  21.197503089904785\n",
      "Loss thresholds for training:  [0.0, 5.299375772476196, 10.598751544952393, 15.898127317428589]\n",
      "Starting from threshold:  3  with value:  15.898127317428589\n",
      "\n",
      "\n",
      "Epoch:  1\n",
      "  Training Loss:  13871.62468723456\n",
      "  Validation Loss:  15.26120376586914\n",
      "  Moving to threshold:  2   |  Next loss benchmark:  10.598751544952393\n",
      "\n",
      "\n",
      "Epoch:  2\n",
      "  Training Loss:  13870.554428080717\n",
      "  Validation Loss:  3.2871150970458984\n",
      "  Moving to threshold:  1   |  Next loss benchmark:  5.299375772476196\n",
      "\n",
      "\n",
      "Epoch:  3\n",
      "  Training Loss:  13869.754569907984\n",
      "  Validation Loss:  2.793699264526367\n",
      "  Moving to threshold:  0   |  Next loss benchmark:  0.0\n",
      "\n",
      "\n",
      "\n",
      "Image sizes entering FC model: \n",
      "\n",
      "{'484002004': [(0, 1794, 0, 2752), (180, 1794, 236, 2712), (0, 1452, 248, 2476), (146, 1452, 31, 2036)], '484002003': [(0, 1488, 0, 3072), (0, 1339, 308, 3072), (0, 1205, 277, 2764), (0, 1084, 249, 2487)], '484004001': [(0, 2732, 0, 2448), (274, 2732, 0, 2203), (210, 2422, 0, 1982), (32, 2022, 28, 1811)], '484004004': [(0, 1320, 0, 2383), (18, 1206, 239, 2383), (16, 1085, 215, 2144), (107, 1069, 193, 1929)], '484004006': [(0, 1328, 0, 1971), (133, 1328, 0, 1773), (0, 1075, 178, 1773), (108, 1075, 160, 1595)]}\n",
      "Switching to fully connected model!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'fc_net' object has no attribute 'sa'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-107a248c0c80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbutler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_attn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/rapids/notebooks/sciclone/geograd/Heather/attn/handler.py\u001b[0m in \u001b[0;36mtrain_attn_model\u001b[0;34m(self, train_dl, val_dl)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Switching to fully connected model!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_fc_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/rapids/notebooks/sciclone/geograd/Heather/attn/handler.py\u001b[0m in \u001b[0;36mtrain_fc_model\u001b[0;34m(self, train_dl, val_dl)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;31m# Prep the input and pass it to the trainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m                 \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprep_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/rapids/notebooks/sciclone/geograd/Heather/attn/handler.py\u001b[0m in \u001b[0;36mprep_input\u001b[0;34m(self, impath)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmuni_id\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'484002003'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;31m# If the muni_id is in the image_sizes dictionary, clip it to the right size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/rapids/notebooks/sciclone/geograd/Heather/attn/handler.py\u001b[0m in \u001b[0;36mtemp\u001b[0;34m(self, cur_image)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;31m# Get the gradcam and the attention heatmap for the current image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0mgradcam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_heatmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_gradcam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_heatmap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    946\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 948\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'fc_net' object has no attribute 'sa'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "butler.train_attn_model(train_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c436d322",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
