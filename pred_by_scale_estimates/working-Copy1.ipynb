{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb673b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import json\n",
    "import PIL\n",
    "\n",
    "\n",
    "from handler import geozoom_handler\n",
    "# from helpers import *\n",
    "from fc_net import *\n",
    "from utils import *\n",
    "from sa import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e98695f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.sample(range(0, len(image_names)), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e99bd8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2066 municipalities.\n"
     ]
    }
   ],
   "source": [
    "image_names = get_png_names(\"../data/MEX/\")#[0:1000]\n",
    "# image_names = get_png_names(\"../pooling/data/MEX2/\")\n",
    "# image_indices = random.sample(range(0, len(image_names)), 1000)\n",
    "# image_names = [image_names[i] for i in range(len(image_names)) if i in image_indices]\n",
    "y = get_migrants(\"../../pooling/data/migration_data.json\" , image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6d0b964",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet18 = models.resnet18().to(device)\n",
    "attn_model = attnNet(resnet = resnet18).to(device)\n",
    "lr = .0001\n",
    "criterion = torch.nn.L1Loss(reduction = 'mean')\n",
    "attn_optimizer = torch.optim.Adam(attn_model.parameters(), lr = lr)\n",
    "\n",
    "butler = geozoom_handler(attn_model, \n",
    "                         device, \n",
    "                         criterion, \n",
    "                         attn_optimizer, \n",
    "                         num_thresholds = 4,\n",
    "                         reduction_percent = .80,\n",
    "                         convergence_dims = (224, 224),\n",
    "                         change_bounds = (-100, 100),\n",
    "                         perc_change_thresh = .55, \n",
    "                         plot = False, \n",
    "                         v = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "210a4975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelfAttention(\n",
       "  (query_conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (key_conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (value_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (softmax): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_model.sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd432881",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "SPLIT = .60\n",
    "\n",
    "train_dl, val_dl = butler.prep_attn_data(image_names, y, SPLIT, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11549f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num training:  1239\n",
      "Num validation:  827\n"
     ]
    }
   ],
   "source": [
    "print(\"Num training: \", len(train_dl))\n",
    "print(\"Num validation: \", len(val_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0589c92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,o in train_dl:\n",
    "#     print(i)\n",
    "# #     print(load_inputs(i[0]).shape, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70395ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch               Training Loss       Validation Loss     Threshold           % within bounds     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/torch/nn/functional.py:3328: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0            1957.2075           1825.0826           3                   \n",
      "Epoch: 1            1900.5738           1840.6055           3                   \n",
      "Epoch: 2            1865.7677           1937.6454           3                   \n",
      "Epoch: 3            1842.6715           1867.246            3                   \n",
      "Epoch: 4            1828.0432           1805.6665           2                   0.993543179983858   \n",
      "Epoch: 5            1819.3786           1834.6394           2                   \n",
      "Epoch: 6            1810.7543           3767.4518           2                   \n",
      "Epoch: 7            1807.6121           1818.395            2                   \n",
      "Epoch: 8            1805.5979           6644.4915           1                   0.9927360774818402  \n",
      "Epoch: 9            1802.3886           2394.424            1                   \n",
      "Epoch: 10           1795.618            4110.073            1                   \n",
      "Epoch: 11           1791.6258           3250.6715           1                   \n"
     ]
    }
   ],
   "source": [
    "butler.train_attn_model(train_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f32635a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MAE:  1455.3926666666669\n"
     ]
    }
   ],
   "source": [
    "butler.train_fc_model(train_dl, val_dl, outside_estimator = 'rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba23bcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "daa4c69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "butler.plot_attn_map(impath = '../data/MEX/484007070/pngs/484007070_2010_all_box484007070_MAY.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877df3c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
