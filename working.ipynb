{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9979b0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import torchvision.models as models\n",
    "from handler import geozoom_handler\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import json\n",
    "import PIL\n",
    "\n",
    "\n",
    "from attn_model2 import *\n",
    "from fc_net import *\n",
    "from helpers import *\n",
    "from utils2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3af45d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.sample(range(0, len(image_names)), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c61c8753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 municipalities.\n"
     ]
    }
   ],
   "source": [
    "# image_names = get_png_names(\"../pooling/data/MEX2/\")#[100:105]\n",
    "image_names = get_png_names(\"../pooling/data/MEX2/\")\n",
    "image_indices = random.sample(range(0, len(image_names)), 5)\n",
    "image_names = [image_names[i] for i in range(len(image_names)) if i in image_indices]\n",
    "y = get_migrants(\"../pooling/data/migration_data.json\" , image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fe8e988",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet18 = models.resnet18().to(device)\n",
    "attn_model = attnNetBinary(in_channels = 512, h = 7, w = 7, batch_size = 1, resnet = resnet18).to(device)\n",
    "lr = .0001\n",
    "criterion = torch.nn.L1Loss(reduction = 'mean')\n",
    "attn_optimizer = torch.optim.Adam(attn_model.parameters(), lr = lr)\n",
    "\n",
    "fc_model = fc_net(resnet = resnet18).to(device)\n",
    "fc_optimizer = torch.optim.Adam(fc_model.parameters(), lr = .01)\n",
    "\n",
    "\n",
    "\n",
    "butler = geozoom_handler(attn_model, fc_model, device, criterion, attn_optimizer, fc_optimizer, plot = False, v = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb38e96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "122d1dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "SPLIT = .90\n",
    "\n",
    "train_dl, val_dl = butler.prep_attn_data(image_names, y, SPLIT, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d6530a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 2083, 1503]) tensor([9.], dtype=torch.float64)\n",
      "torch.Size([1, 3, 476, 619]) tensor([536.], dtype=torch.float64)\n",
      "torch.Size([1, 3, 1987, 1725]) tensor([6205.], dtype=torch.float64)\n",
      "torch.Size([1, 3, 535, 538]) tensor([299.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for i,o in train_dl:\n",
    "    print(load_inputs(i[0]).shape, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d8f6e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350.7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "501 * .70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1491ab72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "  Training Loss:  1758.019072175026\n",
      "Loss thresholds for training:  [0.0, 251.1455817392894, 502.2911634785788, 753.4367452178683, 1004.5823269571576, 1255.727908696447, 1506.8734904357366]\n",
      "Starting from threshold:  6  with value:  1506.8734904357366\n",
      "\n",
      "\n",
      "Epoch:  1\n",
      "  Training Loss:  1735.269968032837\n",
      "\n",
      "\n",
      "Epoch:  2\n",
      "  Training Loss:  1644.836441040039\n",
      "\n",
      "\n",
      "Epoch:  3\n",
      "  Training Loss:  1680.7976684570312\n",
      "\n",
      "\n",
      "Epoch:  4\n",
      "  Training Loss:  1674.3608646392822\n",
      "\n",
      "\n",
      "Epoch:  5\n",
      "  Training Loss:  1538.979995727539\n",
      "\n",
      "\n",
      "Epoch:  6\n",
      "  Training Loss:  1516.752965927124\n",
      "\n",
      "\n",
      "Epoch:  7\n",
      "  Training Loss:  1518.8199672698975\n",
      "\n",
      "\n",
      "Epoch:  8\n",
      "  Training Loss:  1516.9652490615845\n",
      "\n",
      "\n",
      "Epoch:  9\n",
      "  Training Loss:  1434.076452255249\n",
      "  Moving to threshold:  5   |  Next loss benchmark:  1255.727908696447\n",
      "\n",
      "\n",
      "484031047\n",
      "old image size:  (535, 538)\n",
      "new image size:  374 376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/torch/nn/functional.py:3328: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "484019040\n",
      "old image size:  (2083, 1503)\n",
      "new image size:  1458 1052\n",
      "\n",
      "\n",
      "484014057\n",
      "old image size:  (476, 619)\n",
      "new image size:  333 433\n",
      "\n",
      "\n",
      "484020183\n",
      "old image size:  (1987, 1725)\n",
      "new image size:  1390 1207\n",
      "\n",
      "\n",
      "Epoch:  10\n",
      "  Training Loss:  1657.4707374572754\n",
      "\n",
      "\n",
      "Epoch:  11\n",
      "  Training Loss:  1599.37548828125\n",
      "\n",
      "\n",
      "Epoch:  12\n",
      "  Training Loss:  1560.3953647613525\n",
      "\n",
      "\n",
      "Epoch:  13\n",
      "  Training Loss:  1555.0896434783936\n",
      "\n",
      "\n",
      "Epoch:  14\n",
      "  Training Loss:  1498.7398624420166\n",
      "\n",
      "\n",
      "Epoch:  15\n",
      "  Training Loss:  1501.0618228912354\n",
      "\n",
      "\n",
      "Epoch:  16\n",
      "  Training Loss:  1512.9911937713623\n",
      "\n",
      "\n",
      "Epoch:  17\n",
      "  Training Loss:  1445.7095069885254\n",
      "\n",
      "\n",
      "Epoch:  18\n",
      "  Training Loss:  1456.145975112915\n",
      "\n",
      "\n",
      "Epoch:  19\n",
      "  Training Loss:  1412.206979751587\n",
      "\n",
      "\n",
      "Epoch:  20\n",
      "  Training Loss:  1367.6400737762451\n",
      "\n",
      "\n",
      "Epoch:  21\n",
      "  Training Loss:  1387.0708312988281\n",
      "\n",
      "\n",
      "Epoch:  22\n",
      "  Training Loss:  1285.8391342163086\n",
      "\n",
      "\n",
      "Epoch:  23\n",
      "  Training Loss:  1119.8451347351074\n",
      "  Moving to threshold:  4   |  Next loss benchmark:  1004.5823269571576\n",
      "\n",
      "\n",
      "484014057\n",
      "old image size:  (333, 433)\n",
      "new image size:  233 303\n",
      "\n",
      "\n",
      "484031047\n",
      "old image size:  (374, 376)\n",
      "new image size:  261 263\n",
      "\n",
      "\n",
      "484020183\n",
      "old image size:  (1390, 1207)\n",
      "new image size:  972 844\n",
      "\n",
      "\n",
      "484019040\n",
      "old image size:  (1458, 1052)\n",
      "new image size:  1020 736\n",
      "\n",
      "\n",
      "Epoch:  24\n",
      "  Training Loss:  1596.4054832458496\n",
      "\n",
      "\n",
      "Epoch:  25\n",
      "  Training Loss:  1615.0994987487793\n",
      "\n",
      "\n",
      "Epoch:  26\n",
      "  Training Loss:  1352.2426376342773\n",
      "\n",
      "\n",
      "Epoch:  27\n",
      "  Training Loss:  1212.2279663085938\n",
      "\n",
      "\n",
      "Epoch:  28\n",
      "  Training Loss:  1078.145435333252\n",
      "\n",
      "\n",
      "Epoch:  29\n",
      "  Training Loss:  1013.5463256835938\n",
      "\n",
      "\n",
      "Epoch:  30\n",
      "  Training Loss:  727.2934589385986\n",
      "  Moving to threshold:  3   |  Next loss benchmark:  753.4367452178683\n",
      "\n",
      "\n",
      "484014057\n",
      "old image size:  (233, 303)\n",
      "new image size:  224 224\n",
      "\n",
      "\n",
      "484020183\n",
      "old image size:  (972, 844)\n",
      "new image size:  680 590\n",
      "\n",
      "\n",
      "484031047\n",
      "old image size:  (261, 263)\n",
      "new image size:  224 224\n",
      "\n",
      "\n",
      "484019040\n",
      "old image size:  (1020, 736)\n",
      "new image size:  714 515\n",
      "\n",
      "\n",
      "Epoch:  31\n",
      "  Training Loss:  2550.390625\n",
      "\n",
      "\n",
      "Epoch:  32\n",
      "  Training Loss:  2240.1230125427246\n",
      "\n",
      "\n",
      "Epoch:  33\n",
      "  Training Loss:  1689.814640045166\n",
      "\n",
      "\n",
      "Epoch:  34\n",
      "  Training Loss:  1357.4728393554688\n",
      "\n",
      "\n",
      "Epoch:  35\n",
      "  Training Loss:  1204.8470449447632\n",
      "\n",
      "\n",
      "Epoch:  36\n",
      "  Training Loss:  1224.2851824760437\n",
      "\n",
      "\n",
      "Epoch:  37\n",
      "  Training Loss:  1117.9071080684662\n",
      "\n",
      "\n",
      "Epoch:  38\n",
      "  Training Loss:  1146.8730473518372\n",
      "\n",
      "\n",
      "Epoch:  39\n",
      "  Training Loss:  1006.5110049247742\n",
      "\n",
      "\n",
      "Epoch:  40\n",
      "  Training Loss:  1022.3980123996735\n",
      "\n",
      "\n",
      "Epoch:  41\n",
      "  Training Loss:  703.4415667057037\n",
      "  Moving to threshold:  2   |  Next loss benchmark:  502.2911634785788\n",
      "\n",
      "\n",
      "484020183\n",
      "old image size:  (680, 590)\n",
      "new image size:  475 413\n",
      "\n",
      "\n",
      "484019040\n",
      "old image size:  (714, 515)\n",
      "new image size:  499 360\n",
      "Image is already at scale, skipping clip.\n",
      "Image is already at scale, skipping clip.\n",
      "\n",
      "\n",
      "Epoch:  42\n",
      "  Training Loss:  1512.3368377685547\n",
      "\n",
      "\n",
      "Epoch:  43\n",
      "  Training Loss:  1385.2252502441406\n",
      "\n",
      "\n",
      "Epoch:  44\n",
      "  Training Loss:  849.6553497314453\n",
      "\n",
      "\n",
      "Epoch:  45\n",
      "  Training Loss:  612.5490074157715\n",
      "\n",
      "\n",
      "Epoch:  46\n",
      "  Training Loss:  369.2802085876465\n",
      "  Moving to threshold:  1   |  Next loss benchmark:  251.1455817392894\n",
      "\n",
      "\n",
      "484019040\n",
      "old image size:  (499, 360)\n",
      "new image size:  349 251\n",
      "\n",
      "\n",
      "484020183\n",
      "old image size:  (475, 413)\n",
      "new image size:  332 289\n",
      "Image is already at scale, skipping clip.\n",
      "Image is already at scale, skipping clip.\n",
      "\n",
      "\n",
      "Epoch:  47\n",
      "  Training Loss:  1531.4788818359375\n",
      "\n",
      "\n",
      "Epoch:  48\n",
      "  Training Loss:  683.9289398193359\n",
      "\n",
      "\n",
      "Epoch:  49\n",
      "  Training Loss:  261.6168327331543\n",
      "\n",
      "\n",
      "Epoch:  50\n",
      "  Training Loss:  692.0449914932251\n",
      "\n",
      "\n",
      "Epoch:  51\n",
      "  Training Loss:  292.9019832611084\n",
      "\n",
      "\n",
      "Epoch:  52\n",
      "  Training Loss:  343.71455478668213\n",
      "\n",
      "\n",
      "Epoch:  53\n",
      "  Training Loss:  312.5447311401367\n",
      "\n",
      "\n",
      "Epoch:  54\n",
      "  Training Loss:  124.97882270812988\n",
      "  Moving to threshold:  0   |  Next loss benchmark:  0.0\n",
      "Image is already at scale, skipping clip.\n",
      "\n",
      "\n",
      "484020183\n",
      "old image size:  (332, 289)\n",
      "new image size:  224 224\n",
      "Image is already at scale, skipping clip.\n",
      "\n",
      "\n",
      "484019040\n",
      "old image size:  (349, 251)\n",
      "new image size:  224 224\n",
      "\n",
      "\n",
      "\n",
      "Image sizes entering FC model: \n",
      "\n",
      "{'484020183': [(0, 1987, 0, 1725), (298, 1688, 258, 1465), (209, 1181, 181, 1025), (145, 825, 126, 716), (101, 576, 87, 500), (71, 403, 61, 350), (54, 278, 32, 256)], '484014057': [(0, 476, 0, 619), (71, 404, 0, 433), (49, 282, 64, 367), (4, 228, 39, 263)], '484019040': [(0, 2083, 0, 1503), (312, 1770, 225, 1277), (218, 1238, 158, 894), (152, 866, 109, 624), (107, 606, 77, 437), (74, 423, 54, 305), (62, 286, 13, 237)], '484031047': [(0, 535, 0, 538), (80, 454, 81, 457), (56, 317, 55, 318), (18, 242, 19, 243)]}\n",
      "Switching to fully connected model!\n",
      "Epoch:  0\n",
      "  Training Loss:  1757.0082530975342\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  1\n",
      "  Training Loss:  1751.3947687149048\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  2\n",
      "  Training Loss:  1740.8782577514648\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  3\n",
      "  Training Loss:  1733.8725843429565\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  4\n",
      "  Training Loss:  1728.8734722137451\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  5\n",
      "  Training Loss:  1713.2325973510742\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  6\n",
      "  Training Loss:  1702.6087608337402\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  7\n",
      "  Training Loss:  1692.9823513031006\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  8\n",
      "  Training Loss:  1678.1159057617188\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  9\n",
      "  Training Loss:  1667.8581047058105\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  10\n",
      "  Training Loss:  1640.2817993164062\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  11\n",
      "  Training Loss:  1623.1792106628418\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  12\n",
      "  Training Loss:  1597.1447296142578\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  13\n",
      "  Training Loss:  1595.0804290771484\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  14\n",
      "  Training Loss:  1614.6261444091797\n",
      "\n",
      "\n",
      "Epoch:  15\n",
      "  Training Loss:  1583.8776321411133\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  16\n",
      "  Training Loss:  1579.2467002868652\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  17\n",
      "  Training Loss:  1555.4404754638672\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  18\n",
      "  Training Loss:  1539.4839820861816\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  19\n",
      "  Training Loss:  1534.5906143188477\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  20\n",
      "  Training Loss:  1518.5051345825195\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  21\n",
      "  Training Loss:  1508.964958190918\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  22\n",
      "  Training Loss:  1485.1150131225586\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  23\n",
      "  Training Loss:  1516.476505279541\n",
      "\n",
      "\n",
      "Epoch:  24\n",
      "  Training Loss:  1515.6879653930664\n",
      "\n",
      "\n",
      "Epoch:  25\n",
      "  Training Loss:  1488.0770416259766\n",
      "\n",
      "\n",
      "Epoch:  26\n",
      "  Training Loss:  1508.5790176391602\n",
      "\n",
      "\n",
      "Epoch:  27\n",
      "  Training Loss:  1496.1838111877441\n",
      "\n",
      "\n",
      "Epoch:  28\n",
      "  Training Loss:  1492.3925552368164\n",
      "\n",
      "\n",
      "Epoch:  29\n",
      "  Training Loss:  1482.2668266296387\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  30\n",
      "  Training Loss:  1462.1138648986816\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  31\n",
      "  Training Loss:  1496.991600036621\n",
      "\n",
      "\n",
      "Epoch:  32\n",
      "  Training Loss:  1483.6652069091797\n",
      "\n",
      "\n",
      "Epoch:  33\n",
      "  Training Loss:  1468.5075340270996\n",
      "\n",
      "\n",
      "Epoch:  34\n",
      "  Training Loss:  1483.9742965698242\n",
      "\n",
      "\n",
      "Epoch:  35\n",
      "  Training Loss:  1474.4403610229492\n",
      "\n",
      "\n",
      "Epoch:  36\n",
      "  Training Loss:  1483.9823760986328\n",
      "\n",
      "\n",
      "Epoch:  37\n",
      "  Training Loss:  1453.5144309997559\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  38\n",
      "  Training Loss:  1465.510341644287\n",
      "\n",
      "\n",
      "Epoch:  39\n",
      "  Training Loss:  1464.1885414123535\n",
      "\n",
      "\n",
      "Epoch:  40\n",
      "  Training Loss:  1461.376033782959\n",
      "\n",
      "\n",
      "Epoch:  41\n",
      "  Training Loss:  1459.3474426269531\n",
      "\n",
      "\n",
      "Epoch:  42\n",
      "  Training Loss:  1457.966453552246\n",
      "\n",
      "\n",
      "Epoch:  43\n",
      "  Training Loss:  1455.0218467712402\n",
      "\n",
      "\n",
      "Epoch:  44\n",
      "  Training Loss:  1447.9021682739258\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  45\n",
      "  Training Loss:  1430.7165184020996\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  46\n",
      "  Training Loss:  1433.7620697021484\n",
      "\n",
      "\n",
      "Epoch:  47\n",
      "  Training Loss:  1439.3178520202637\n",
      "\n",
      "\n",
      "Epoch:  48\n",
      "  Training Loss:  1419.7633666992188\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  49\n",
      "  Training Loss:  1417.6621017456055\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  50\n",
      "  Training Loss:  1409.246150970459\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  51\n",
      "  Training Loss:  1404.656795501709\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  52\n",
      "  Training Loss:  1411.9250717163086\n",
      "\n",
      "\n",
      "Epoch:  53\n",
      "  Training Loss:  1420.4740562438965\n",
      "\n",
      "\n",
      "Epoch:  54\n",
      "  Training Loss:  1407.975399017334\n",
      "\n",
      "\n",
      "Epoch:  55\n",
      "  Training Loss:  1389.5033493041992\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  56\n",
      "  Training Loss:  1389.8660202026367\n",
      "\n",
      "\n",
      "Epoch:  57\n",
      "  Training Loss:  1390.5571174621582\n",
      "\n",
      "\n",
      "Epoch:  58\n",
      "  Training Loss:  1379.7448539733887\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  59\n",
      "  Training Loss:  1373.8629035949707\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  60\n",
      "  Training Loss:  1367.3989715576172\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  61\n",
      "  Training Loss:  1372.0461959838867\n",
      "\n",
      "\n",
      "Epoch:  62\n",
      "  Training Loss:  1366.2807273864746\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  63\n",
      "  Training Loss:  1360.6573677062988\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  64\n",
      "  Training Loss:  1356.6953468322754\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  65\n",
      "  Training Loss:  1345.598388671875\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  66\n",
      "  Training Loss:  1350.831184387207\n",
      "\n",
      "\n",
      "Epoch:  67\n",
      "  Training Loss:  1363.5698509216309\n",
      "\n",
      "\n",
      "Epoch:  68\n",
      "  Training Loss:  1408.923053741455\n",
      "\n",
      "\n",
      "Epoch:  69\n",
      "  Training Loss:  1367.7019882202148\n",
      "\n",
      "\n",
      "Epoch:  70\n",
      "  Training Loss:  1358.8650665283203\n",
      "\n",
      "\n",
      "Epoch:  71\n",
      "  Training Loss:  1361.961513519287\n",
      "\n",
      "\n",
      "Epoch:  72\n",
      "  Training Loss:  1360.8915481567383\n",
      "\n",
      "\n",
      "Epoch:  73\n",
      "  Training Loss:  1373.880111694336\n",
      "\n",
      "\n",
      "Epoch:  74\n",
      "  Training Loss:  1333.7315826416016\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  75\n",
      "  Training Loss:  1377.0470008850098\n",
      "\n",
      "\n",
      "Epoch:  76\n",
      "  Training Loss:  1316.9304695129395\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  77\n",
      "  Training Loss:  1329.808795928955\n",
      "\n",
      "\n",
      "Epoch:  78\n",
      "  Training Loss:  1301.265697479248\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  79\n",
      "  Training Loss:  1307.3769302368164\n",
      "\n",
      "\n",
      "Epoch:  80\n",
      "  Training Loss:  1291.127052307129\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  81\n",
      "  Training Loss:  1260.9218254089355\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  82\n",
      "  Training Loss:  1262.019374847412\n",
      "\n",
      "\n",
      "Epoch:  83\n",
      "  Training Loss:  1249.1143798828125\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  84\n",
      "  Training Loss:  1245.165096282959\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  85\n",
      "  Training Loss:  1229.4755325317383\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  86\n",
      "  Training Loss:  1224.175090789795\n",
      "Updating best weights!\n",
      "\n",
      "\n",
      "Epoch:  87\n",
      "  Training Loss:  1236.2695045471191\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "butler.train_attn_model(train_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6395317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'484024023': [(0, 1126, 0, 1507),\n",
       "  (168, 956, 226, 1280),\n",
       "  (117, 668, 157, 894),\n",
       "  (82, 467, 110, 625),\n",
       "  (57, 326, 77, 437),\n",
       "  (22, 246, 67, 291)],\n",
       " '484020565': [(0, 470, 0, 395), (70, 399, 59, 335), (52, 276, 26, 250)],\n",
       " '484021030': [(0, 217, 0, 124)],\n",
       " '484021171': [(0, 195, 0, 170)]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "butler.image_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6669bdb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([6, 5, 4, 3, 2, 1, 'fc'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "butler.threshold_weights.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19e5aeb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1126, 1507])\n",
      "torch.Size([1, 3, 470, 395])\n",
      "torch.Size([1, 3, 217, 124])\n",
      "torch.Size([1, 3, 195, 170])\n"
     ]
    }
   ],
   "source": [
    "for i,o in train_dl:\n",
    "    print(load_inputs(i[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be087a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "448.7"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "641 * .70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d30dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "263 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41712077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, o in train_dl:\n",
    "    \n",
    "    muni_id = i[0].split(\"/\")[4]\n",
    "    \n",
    "    plt.imshow(butler.prep_input(i).detach().cpu()[0].permute(1,2,0))\n",
    "    plt.title(butler.image_sizes[muni_id])\n",
    "    plt.savefig(f\"test{muni_id}.png\")\n",
    "    \n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7706114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for i in range(50):\n",
    "# while handler.threshold_index > 0:\n",
    "\n",
    "#     for impath, output in train_dl:\n",
    "\n",
    "#         # Prep the input and pass it to the trainer (this could easily be done in one step eventually if ya want)\n",
    "#         input = handler.prep_input(impath)\n",
    "#         handler.train(input, output)\n",
    "    \n",
    "#     handler.end_epoch(train_dl, val_dl = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a9ec8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'484002003': (0, 224, 0, 224),\n",
       " '484016045': (0, 224, 0, 224),\n",
       " '484020489': (0, 224, 0, 224),\n",
       " '484020254': (0, 224, 0, 224)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handler.image_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5bdacab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([6, 5, 4, 3, 2, 1, 'fc'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "butler.threshold_weights.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0132eff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('../pooling/data/MEX2/484020535/pngs/484020535_2010_1_box484020535_MAY.png',) tensor([89.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for i, o in val_dl:\n",
    "    print(i, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9192fd15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a9f323d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201.76       196.0\n",
      "201.08       4.0\n",
      "273.5       606.0\n",
      "4416.25       6521.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def run_validation(attn_model, fc_model, input, weights_dict, plot = False):\n",
    "    \n",
    "    muni_id = input[0].split(\"/\")[4]\n",
    "    cur_image = load_inputs(input[0])    \n",
    "    \n",
    "    for k in weights_dict.keys():\n",
    "                \n",
    "        if k != 'fc':\n",
    "            \n",
    "            model = attn_model\n",
    "            model.load_state_dict(weights_dict[k])\n",
    "            model.eval()\n",
    "            IM_SIZE = (cur_image.shape[2], cur_image.shape[3])\n",
    "            gradcam, attn_heatmap = get_gradcam(model, IM_SIZE, cur_image.cuda()) \n",
    "            cur_image, new_dims = butler.clip_input(cur_image, attn_heatmap)\n",
    "            \n",
    "            if plot == True:\n",
    "            \n",
    "                plot_gradcam(gradcam)\n",
    "                plt.savefig(f\"threshold{k}_muni{muni_id}.png\")\n",
    "                plt.clf()\n",
    "            \n",
    "        \n",
    "        if k == 'fc':\n",
    "            \n",
    "            model = fc_model\n",
    "            model.load_state_dict(weights_dict[k])\n",
    "            model.eval()\n",
    "            return model(cur_image.cuda()).item()\n",
    "            \n",
    "\n",
    "        \n",
    "for i, o in train_dl:\n",
    "\n",
    "    print(round(run_validation(attn_model, fc_model, i, butler.threshold_weights), 2), \"     \", o.item())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701df4b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
