{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7295f51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "\n",
    "\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import numpy as nps\n",
    "import random\n",
    "import torch\n",
    "import json\n",
    "import PIL\n",
    "\n",
    "\n",
    "from handler import geozoom_handler\n",
    "# from helpers import *\n",
    "from fc_net import *\n",
    "from utils import *\n",
    "from sa import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd23debd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 municipalities.\n"
     ]
    }
   ],
   "source": [
    "image_names = get_png_names(\"../data/MEX/\")#[0:5]\n",
    "# image_names = get_png_names(\"../pooling/data/MEX2/\")\n",
    "image_indices = random.sample(range(0, len(image_names)), 200)\n",
    "image_names = [image_names[i] for i in range(len(image_names)) if i in image_indices]\n",
    "y = get_migrants(\"../../pooling/data/migration_data.json\" , image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83a1f7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet18 = models.resnet18().to(device)\n",
    "attn_model = attnNet(resnet = resnet18).to(device)\n",
    "lr = .0001\n",
    "criterion = torch.nn.L1Loss(reduction = 'mean')\n",
    "attn_optimizer = torch.optim.Adam(attn_model.parameters(), lr = lr)\n",
    "\n",
    "fc_model = fc_net(resnet = resnet18).to(device)\n",
    "fc_optimizer = torch.optim.Adam(fc_model.parameters(), lr = .0001)\n",
    "\n",
    "butler = geozoom_handler(attn_model, \n",
    "                         device, \n",
    "                         criterion, \n",
    "                         attn_optimizer, \n",
    "                         fc_model = fc_model,\n",
    "                         fc_optimizer = fc_optimizer,\n",
    "                         fc_batch_size = 4,\n",
    "                         reduction_percent = .70,\n",
    "                         max_to_change = 5, \n",
    "                         plot = False, \n",
    "                         v = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acfb017f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image convergence dimensions:  (62, 118)\n",
      "\n",
      "Number of training images:  120\n",
      "Number of validation images:  80\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 1\n",
    "SPLIT = .60\n",
    "\n",
    "train_dl, val_dl = butler.prep_attn_data(image_names, y, SPLIT, BATCH_SIZE)\n",
    "\n",
    "print(\"\\nNumber of training images: \", len(train_dl))\n",
    "print(\"Number of validation images: \", len(val_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bd7b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch               Training Loss       Validation Loss     # times clipped     # images at scale   % above max         \n",
      "Epoch: 0            2159.5928           2157.6398           0                   0                   0                   \n",
      "Epoch: 1            2152.8167           2152.6634           0                   0                   0                   \n",
      "Epoch: 2            2147.035            2143.2077           0                   0                   0                   \n",
      "Epoch: 3            2140.7318           2145.9463           0                   0                   0                   \n",
      "Epoch: 4            2134.1025           2141.13             0                   0                   0.13333333333333333 \n",
      "Epoch: 5            2127.5044           2138.0042           0                   0                   0.2916666666666667  \n",
      "Epoch: 6            2120.531            2130.1758           1                   1                   0.5333333333333333  \n",
      "Epoch: 7            2112.8258           2120.725            1                   1                   0                   \n",
      "Epoch: 8            2105.6478           2127.9594           1                   1                   0                   \n",
      "Epoch: 9            2098.949            2126.5173           1                   1                   0                   \n",
      "Epoch: 10           2092.5969           2112.2184           1                   1                   0.075               \n",
      "Epoch: 11           2086.7583           2109.279            1                   1                   0.23333333333333334 \n",
      "Epoch: 12           2080.9999           2105.3574           1                   1                   0.4                 \n",
      "Epoch: 13           2075.6521           2097.3164           2                   4                   0.5583333333333333  \n",
      "Epoch: 14           2069.4315           2094.4251           2                   4                   0                   \n",
      "Epoch: 15           2062.9132           2085.3864           2                   4                   0                   \n",
      "Epoch: 16           2056.4668           2094.1654           2                   4                   0                   \n",
      "Epoch: 17           2050.7242           2091.3312           2                   4                   0.075               \n",
      "Epoch: 18           2044.8667           2086.2931           2                   4                   0.25                \n",
      "Epoch: 19           2039.7489           2089.4842           2                   4                   0.43333333333333335 \n",
      "Epoch: 20           2035.255            2095.4543           3                   16                  0.6333333333333333  \n",
      "Epoch: 21           2032.1209           2067.0898           3                   16                  0                   \n",
      "Epoch: 22           2028.1764           2069.1278           3                   16                  0                   \n",
      "Epoch: 23           2025.5416           2059.4656           3                   16                  0                   \n",
      "Epoch: 24           2022.9292           2070.7853           3                   16                  0.058333333333333334\n",
      "Epoch: 25           2018.6782           2074.5008           3                   16                  0.35                \n",
      "Epoch: 26           2015.3008           2072.8539           3                   16                  0.475               \n",
      "Epoch: 27           2012.6815           2077.2023           4                   40                  0.6083333333333333  \n",
      "Epoch: 28           2009.8883           2070.0239           4                   40                  0                   \n",
      "Epoch: 29           2007.2712           2068.0405           4                   40                  0                   \n"
     ]
    }
   ],
   "source": [
    "butler.train_attn_model(train_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2627f71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "butler.go_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7888c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,o in train_dl:\n",
    "    print(load_inputs(i[0]).shape, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22df68fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_im_dims(im_sizes):\n",
    "    \n",
    "#     for muni, size in im_sizes.items():\n",
    "        \n",
    "#         last_size = size[-1]\n",
    "        \n",
    "#         w, h = last_size[1] - last_size[0], last_size[3] - last_size[2]\n",
    "        \n",
    "#         print(muni, w, h)\n",
    "        \n",
    "# get_im_dims(butler.image_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c460d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd586c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attn_map(impath):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to save the attention maps for a given image at each threshold\n",
    "    \"\"\"\n",
    "\n",
    "    muni_id = impath.split(\"/\")[3]\n",
    "    cur_image = load_inputs(impath)\n",
    "    folder = f\"{muni_id}_attention_maps\"\n",
    "\n",
    "    if not os.path.isdir(folder):\n",
    "        os.mkdir(folder)\n",
    "\n",
    "\n",
    "    for k in butler.threshold_weights.keys():\n",
    "        \n",
    "        print(k)\n",
    "\n",
    "        if k != 'fc':\n",
    "\n",
    "            model = butler.attn_model\n",
    "            model.load_state_dict(butler.threshold_weights[k])\n",
    "            model.eval()\n",
    "            IM_SIZE = (cur_image.shape[2], cur_image.shape[3])\n",
    "            gradcam, attn_heatmap = get_gradcam(model, IM_SIZE, cur_image.cuda(), target_layer = model.sa) \n",
    "            cur_image, new_dims = butler.clip_input(cur_image, attn_heatmap)\n",
    "\n",
    "            fname = os.path.join(f\"{muni_id}_attention_maps\", f\"threshold{k}_muni{muni_id}.png\") \n",
    "\n",
    "            plot_gradcam(gradcam)\n",
    "            plt.savefig(fname)\n",
    "            plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec887026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "butler.plot_attn_map(impath = '../data/MEX/484031098/pngs/484031098_2010_all_box484031098_MAY.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36d17ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faa25ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
