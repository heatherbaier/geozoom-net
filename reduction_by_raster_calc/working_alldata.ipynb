{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d812a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import numpy as nps\n",
    "import random\n",
    "import torch\n",
    "import json\n",
    "import PIL\n",
    "\n",
    "\n",
    "from handler import geozoom_handler\n",
    "# from helpers import *\n",
    "from fc_net import *\n",
    "from utils import *\n",
    "from sa import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b1d2398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2066 municipalities.\n"
     ]
    }
   ],
   "source": [
    "image_names = get_png_names(\"../data/MEX/\")#[0:5]\n",
    "# image_names = get_png_names(\"../pooling/data/MEX2/\")\n",
    "# image_indices = random.sample(range(0, len(image_names)), 200)\n",
    "# image_names = [image_names[i] for i in range(len(image_names)) if i in image_indices]\n",
    "y = get_migrants(\"../../pooling/data/migration_data.json\" , image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6694f708",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet18 = models.resnet18().to(device)\n",
    "attn_model = attnNet(resnet = resnet18).to(device)\n",
    "lr = .0001\n",
    "criterion = torch.nn.L1Loss(reduction = 'mean')\n",
    "attn_optimizer = torch.optim.Adam(attn_model.parameters(), lr = lr)\n",
    "\n",
    "fc_model = fc_net(resnet = resnet18).to(device)\n",
    "fc_optimizer = torch.optim.Adam(fc_model.parameters(), lr = .0001)\n",
    "\n",
    "butler = geozoom_handler(attn_model, \n",
    "                         device, \n",
    "                         criterion, \n",
    "                         attn_optimizer, \n",
    "                         fc_model = fc_model,\n",
    "                         fc_optimizer = fc_optimizer,\n",
    "                         fc_batch_size = 64,\n",
    "                         num_fc_epochs = 250,\n",
    "                         reduction_percent = .70,\n",
    "                         max_to_change = 5, \n",
    "                         plot = False, \n",
    "                         v = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ac4f1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image convergence dimensions:  (55, 55)\n",
      "\n",
      "Number of training images:  1239\n",
      "Number of validation images:  827\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 1\n",
    "SPLIT = .60\n",
    "\n",
    "train_dl, val_dl = butler.prep_attn_data(image_names, y, SPLIT, BATCH_SIZE)\n",
    "\n",
    "print(\"\\nNumber of training images: \", len(train_dl))\n",
    "print(\"Number of validation images: \", len(val_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353be78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch               Training Loss       Validation Loss     # times clipped     # images at scale   % above max         \n",
      "Epoch: 0            1948.5769           1947.0966           0                   0                   0                   \n",
      "Epoch: 1            1891.496            1931.3005           0                   0                   0                   \n"
     ]
    }
   ],
   "source": [
    "butler.train_attn_model(train_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9e2ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "butler.go_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc08c2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,o in train_dl:\n",
    "    print(load_inputs(i[0]).shape, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2a7378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_im_dims(im_sizes):\n",
    "    \n",
    "#     for muni, size in im_sizes.items():\n",
    "        \n",
    "#         last_size = size[-1]\n",
    "        \n",
    "#         w, h = last_size[1] - last_size[0], last_size[3] - last_size[2]\n",
    "        \n",
    "#         print(muni, w, h)\n",
    "        \n",
    "# get_im_dims(butler.image_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19b9a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d429b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attn_map(impath):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to save the attention maps for a given image at each threshold\n",
    "    \"\"\"\n",
    "\n",
    "    muni_id = impath.split(\"/\")[3]\n",
    "    cur_image = load_inputs(impath)\n",
    "    folder = f\"{muni_id}_attention_maps\"\n",
    "\n",
    "    if not os.path.isdir(folder):\n",
    "        os.mkdir(folder)\n",
    "\n",
    "\n",
    "    for k in butler.threshold_weights.keys():\n",
    "        \n",
    "        print(k)\n",
    "\n",
    "        if k != 'fc':\n",
    "\n",
    "            model = butler.attn_model\n",
    "            model.load_state_dict(butler.threshold_weights[k])\n",
    "            model.eval()\n",
    "            IM_SIZE = (cur_image.shape[2], cur_image.shape[3])\n",
    "            gradcam, attn_heatmap = get_gradcam(model, IM_SIZE, cur_image.cuda(), target_layer = model.sa) \n",
    "            cur_image, new_dims = butler.clip_input(cur_image, attn_heatmap)\n",
    "\n",
    "            fname = os.path.join(f\"{muni_id}_attention_maps\", f\"threshold{k}_muni{muni_id}.png\") \n",
    "\n",
    "            plot_gradcam(gradcam)\n",
    "            plt.savefig(fname)\n",
    "            plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72c2b378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "butler.plot_attn_map(impath = '../data/MEX/484031098/pngs/484031098_2010_all_box484031098_MAY.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e76a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8f6b94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
